{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d277aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import GridMDP\n",
    "import time, random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4x3 World\n",
    "grid1 = [\n",
    "    [0, 0, 0, +1],\n",
    "    [0, None, 0, -1],\n",
    "    [0, 0, 0, 0]\n",
    "]\n",
    "terminals1 = [(0,3), (1,3)]\n",
    "mdp1 = GridMDP(grid1, terminals1, gamma=0.9)\n",
    "\n",
    "# 5x5 World\n",
    "grid2 = [\n",
    "    [0, 0, 0, 0, +1],\n",
    "    [0, None, None, 0, -1],\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, None, 0, None, 0],\n",
    "    [0, 0, 0, 0, 0]\n",
    "]\n",
    "terminals2 = [(0,4), (1,4)]\n",
    "mdp2 = GridMDP(grid2, terminals2, gamma=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e658767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp, gamma=0.9, theta=1e-3):\n",
    "    U = {s: 0 for s in mdp.states}\n",
    "    delta_history = []\n",
    "    iteration = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        delta = 0\n",
    "        U_new = U.copy()\n",
    "        for s in mdp.states:\n",
    "            if s in mdp.terminals: \n",
    "                continue\n",
    "            U_new[s] = max(\n",
    "                sum(p * (mdp.R(s) + gamma * U[s1]) for (p, s1) in mdp.T(s,a))\n",
    "                for a in mdp.actions(s)\n",
    "            )\n",
    "            delta = max(delta, abs(U_new[s] - U[s]))\n",
    "        U = U_new\n",
    "        delta_history.append(delta)\n",
    "        if delta < theta: break\n",
    "\n",
    "    policy = {s: None if s in mdp.terminals else\n",
    "              max(mdp.actions(s), key=lambda a: sum(p*(mdp.R(s)+gamma*U[s1]) for (p,s1) in mdp.T(s,a)))\n",
    "              for s in mdp.states}\n",
    "\n",
    "    return U, policy, {\"iterations\": iteration, \"delta_history\": delta_history, \"time\": time.time()-start_time}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6531855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(mdp, pi, gamma=0.9, theta=1e-3):\n",
    "    U = {s: 0 for s in mdp.states}\n",
    "    while True:\n",
    "        delta = 0\n",
    "        U_new = U.copy()\n",
    "        for s in mdp.states:\n",
    "            if s in mdp.terminals: continue\n",
    "            a = pi[s]\n",
    "            U_new[s] = sum(p*(mdp.R(s)+gamma*U[s1]) for (p,s1) in mdp.T(s,a))\n",
    "            delta = max(delta, abs(U_new[s]-U[s]))\n",
    "        U = U_new\n",
    "        if delta < theta: break\n",
    "    return U\n",
    "\n",
    "def policy_iteration(mdp, gamma=0.9, theta=1e-3):\n",
    "    pi = {s: random.choice(mdp.actions(s)) if s not in mdp.terminals else None for s in mdp.states}\n",
    "    iteration = 0\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        U = policy_evaluation(mdp, pi, gamma, theta)\n",
    "        stable = True\n",
    "        for s in mdp.states:\n",
    "            if s in mdp.terminals: continue\n",
    "            old = pi[s]\n",
    "            pi[s] = max(mdp.actions(s), key=lambda a: sum(p*(mdp.R(s)+gamma*U[s1]) for (p,s1) in mdp.T(s,a)))\n",
    "            if old != pi[s]: stable = False\n",
    "        if stable: break\n",
    "    return U, pi, {\"iterations\": iteration, \"time\": time.time()-start_time}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_value_iteration(mdp, gamma=0.9, theta=1e-3):\n",
    "    U = {s: 0 for s in mdp.states}\n",
    "    iteration, delta_history = 0, []\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        delta = 0\n",
    "        for s in mdp.states:  \n",
    "            if s in mdp.terminals: continue\n",
    "            u = U[s]\n",
    "            U[s] = max(sum(p*(mdp.R(s)+gamma*U[s1]) for (p,s1) in mdp.T(s,a)) for a in mdp.actions(s))\n",
    "            delta = max(delta, abs(u-U[s]))\n",
    "        delta_history.append(delta)\n",
    "        if delta < theta: break\n",
    "\n",
    "    pi = {s: None if s in mdp.terminals else\n",
    "          max(mdp.actions(s), key=lambda a: sum(p*(mdp.R(s)+gamma*U[s1]) for (p,s1) in mdp.T(s,a)))\n",
    "          for s in mdp.states}\n",
    "    return U, pi, {\"iterations\": iteration, \"delta_history\": delta_history, \"time\": time.time()-start_time}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritized_sweeping(mdp, gamma=0.9, theta=1e-3):\n",
    "    U = {s: 0 for s in mdp.states}\n",
    "    pq = []\n",
    "    start_time = time.time()\n",
    "    iteration = 0\n",
    "\n",
    "    def residual(s):\n",
    "        if s in mdp.terminals: return 0\n",
    "        best = max(sum(p*(mdp.R(s)+gamma*U[s1]) for (p,s1) in mdp.T(s,a)) for a in mdp.actions(s))\n",
    "        return abs(best - U[s])\n",
    "\n",
    "    for s in mdp.states:\n",
    "        heapq.heappush(pq, (-residual(s), s))\n",
    "\n",
    "    while pq:\n",
    "        iteration += 1\n",
    "        _, s = heapq.heappop(pq)\n",
    "        if residual(s) < theta: continue\n",
    "        U[s] = max(sum(p*(mdp.R(s)+gamma*U[s1]) for (p,s1) in mdp.T(s,a)) for a in mdp.actions(s))\n",
    "        heapq.heappush(pq, (-residual(s), s))\n",
    "\n",
    "    pi = {s: None if s in mdp.terminals else\n",
    "          max(mdp.actions(s), key=lambda a: sum(p*(mdp.R(s)+gamma*U[s1]) for (p,s1) in mdp.T(s,a)))\n",
    "          for s in mdp.states}\n",
    "    return U, pi, {\"iterations\": iteration, \"time\": time.time()-start_time}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = {\n",
    "    \"VI\": value_iteration,\n",
    "    \"PI\": policy_iteration,\n",
    "    \"AsyncVI\": async_value_iteration,\n",
    "    \"PS\": prioritized_sweeping\n",
    "}\n",
    "\n",
    "results = []\n",
    "for algo, func in algos.items():\n",
    "    for mdp, name in [(mdp1,\"4x3\"), (mdp2,\"5x5\")]:\n",
    "        U, pi, stats = func(mdp, gamma=0.9, theta=1e-3)\n",
    "        results.append({\n",
    "            \"algo\": algo,\n",
    "            \"map\": name,\n",
    "            \"iterations\": stats.get(\"iterations\",None),\n",
    "            \"time\": stats[\"time\"]\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
